version: 2.1

jobs:
  test-csm:
    docker:
      - image: cimg/python:3.10  # Using the official Python 3.10 image
    working_directory: ~/repo
    steps:
      - checkout

      - run:
          name: Debug Environment
          command: |
            echo "Python version:"
            python --version
            echo "Python location:"
            which python
            echo "Current directory:"
            pwd
            echo "Directory contents:"
            ls -la

      - run:
          name: Install System Dependencies
          command: |
            sudo apt-get update
            sudo apt-get install -y ffmpeg
            echo "✅ System dependencies installed."

      - run:
          name: Install Dependencies
          command: |
            set -x  # Enable verbose mode
            python3 -m venv .venv
            echo "✅ Virtual environment created."
            source .venv/bin/activate
            echo "Python executable in use: $(which python)"
            echo "✅ Virtual environment activated."
            pip install --upgrade pip
            pip list  # Show initial packages
            echo "Installing requirements..."
            pip install -r requirements.txt
            echo "Installing huggingface_hub..."
            pip install --verbose huggingface_hub
            pip list  # Show installed packages
            echo "✅ Dependencies installed."

      - run:
          name: Verify Python Paths
          command: |
            source .venv/bin/activate
            echo "Python path:"
            python -c "import sys; print(sys.path)"
            echo "Python executable:"
            python -c "import sys; print(sys.executable)"

      - run:
          name: Verify Hugging Face CLI Installation
          command: |
            source .venv/bin/activate
            python -c "import huggingface_hub; print('huggingface_hub version:', huggingface_hub.__version__)"
            python -c "import huggingface_hub; print('huggingface_hub path:', huggingface_hub.__file__)"
            echo "Listing huggingface_hub contents:"
            python -c "import huggingface_hub; print(dir(huggingface_hub))"

      - run:
          name: Log in to Hugging Face
          environment:
            HUGGINGFACE_TOKEN: $HUGGINGFACE_TOKEN  # Ensure this is set in your CircleCI project settings
          command: |
            source .venv/bin/activate
            echo "Logging in to Hugging Face using API method..."
            python -c "from huggingface_hub import login; login(token='$HUGGINGFACE_TOKEN'); print('✅ Hugging Face login successful.')"

      - run:
          name: Debug Generator Module
          command: |
            source .venv/bin/activate
            echo "Examining generator.py..."
            cat generator.py
            echo "Checking Model class implementation..."
            python -c "import inspect; from generator import Model; print('Model class __init__ signature:', inspect.signature(Model.__init__)); print('Model class from_pretrained signature:', inspect.signature(Model.from_pretrained)); from generator import load_csm_1b; print('load_csm_1b signature:', inspect.signature(load_csm_1b))"

      - run:
          name: Run Basic Speech Generation Test
          command: |
            source .venv/bin/activate
            echo "Python and torch versions:"
            python -c "import sys, torch; print(f'Python: {sys.version}'); print(f'PyTorch: {torch.__version__}')"
            echo "Starting generation test with improved error handling..."
            python -c "try:
    from generator import load_csm_1b, Model
    import torchaudio, torch
    import json, os
    print('Modules imported successfully')
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f'Using device: {device}')
    print('Checking if model config exists...')
    from huggingface_hub import hf_hub_download
    try:
        config_path = hf_hub_download('sesame/csm-1b', 'config.json')
        with open(config_path, 'r') as f:
            config = json.load(f)
        print('Config loaded successfully')
    except Exception as e:
        print(f'Error loading config: {e}')
        config = None
    print('Attempting to load model...')
    generator = load_csm_1b(device=device)
    print('Model loaded successfully')
    audio = generator.generate(text='Are you coming, or am I just waiting here forever?', speaker=0, context=[], max_audio_length_ms=10000)
    print('Audio generated successfully')
    torchaudio.save('test_output.wav', audio.unsqueeze(0).cpu(), generator.sample_rate)
    print('✅ Test completed successfully!')
except Exception as e:
    import traceback
    print(f'Error during test: {e}')
    traceback.print_exc()
    exit(1)"

      - store_artifacts:
          name: Generated Audio File
          path: test_output.wav

      - store_artifacts:
          name: generator.py File
          path: generator.py

      - run:
          name: Cleanup
          command: rm -rf .venv

workflows:
  version: 2
  test_csm_workflow:
    jobs:
      - test-csm
