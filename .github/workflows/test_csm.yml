name: Test CSM Model
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
jobs:
  test-csm:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Debug environment
        run: |
          echo "Python version:"
          python --version
          echo "Python location:"
          which python
          echo "Current directory:"
          pwd
          echo "Directory contents:"
          ls -la
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          echo "✅ System dependencies installed."
      
      - name: Install dependencies
        run: |
          set -x  # Enable verbose mode
          python3 -m venv .venv
          echo "✅ Virtual environment created."
          source .venv/bin/activate
          echo "Python executable in use: $(which python)"
          echo "✅ Virtual environment activated."
          pip install --upgrade pip
          pip list  # Show initial packages
          echo "Installing requirements..."
          pip install -r requirements.txt
          echo "Installing huggingface_hub..."
          pip install --verbose huggingface_hub
          pip list  # Show installed packages
          echo "✅ Dependencies installed."
      
      - name: Verify Python paths
        run: |
          source .venv/bin/activate
          echo "Python path:"
          python -c "import sys; print(sys.path)"
          echo "Python executable:"
          python -c "import sys; print(sys.executable)"
      
      - name: Verify Hugging Face CLI installation
        run: |
          source .venv/bin/activate
          python -c "import huggingface_hub; print('huggingface_hub version:', huggingface_hub.__version__)"
          python -c "import huggingface_hub; print('huggingface_hub path:', huggingface_hub.__file__)"
          echo "Listing huggingface_hub contents:"
          python -c "import huggingface_hub; print(dir(huggingface_hub))"
      
      - name: Log in to Hugging Face
        env:
          HUGGINGFACE_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
        run: |
          source .venv/bin/activate
          echo "Logging in to Hugging Face using API method..."
          python -c "
          from huggingface_hub import login
          login(token='$HUGGINGFACE_TOKEN')
          print('✅ Hugging Face login successful.')
          "
      
      - name: Run optimized speech generation test
        run: |
          source .venv/bin/activate
          echo "Python and torch versions:"
          python -c "import sys, torch; print(f'Python: {sys.version}'); print(f'PyTorch: {torch.__version__}')"
          echo "Starting generation test with optimizations..."
          python -c "
          try:
              from generator import load_csm_1b, Model
              import torchaudio, torch
              import time
              
              print('Modules imported successfully')
              device = 'cuda' if torch.cuda.is_available() else 'cpu'
              print(f'Using device: {device}')
              
              start_time = time.time()
              print('Loading model with optimizations...')
              generator = load_csm_1b(
                  device=device, 
                  use_float16=(device=='cpu'),  # Use float16 on CPU
                  enable_watermarking=False     # Disable watermarking for speed
              )
              print(f'Model loaded in {time.time() - start_time:.2f} seconds')
              
              print('Generating audio...')
              gen_start = time.time()
              audio = generator.generate(
                  text='Are you coming, or am I just waiting here forever?', 
                  speaker=0, 
                  context=[], 
                  max_audio_length_ms=5000,  # Shorter for faster tests
                  apply_watermark=False      # Disable watermarking
              )
              gen_time = time.time() - gen_start
              print(f'Audio generated in {gen_time:.2f} seconds')
              
              torchaudio.save('test_output.wav', audio.unsqueeze(0).cpu(), generator.sample_rate)
              print('✅ Test completed successfully!')
              total_time = time.time() - start_time
              print(f'Total processing time: {total_time:.2f} seconds')
          except Exception as e:
              import traceback
              print(f'Error during test: {e}')
              traceback.print_exc()
              exit(1)
          "
      
      - name: Upload generated audio file
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: generated-audio
          path: |
            test_output.wav
            **/generator.py
          if-no-files-found: ignore
      
      - name: Cleanup
        if: always()
        run: rm -rf .venv
